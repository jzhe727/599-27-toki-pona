{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 1.0,
  "global_step": 21370,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 13.49306583404541,
      "learning_rate": 4e-08,
      "loss": 5.8337,
      "step": 1
    },
    {
      "epoch": 0.23,
      "grad_norm": 8.167996406555176,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 4.3675,
      "step": 500
    },
    {
      "epoch": 0.47,
      "grad_norm": 9.349684715270996,
      "learning_rate": 1.9521801629132728e-05,
      "loss": 3.6527,
      "step": 1000
    },
    {
      "epoch": 0.7,
      "grad_norm": 11.094407081604004,
      "learning_rate": 1.9042644944896982e-05,
      "loss": 3.4854,
      "step": 1500
    },
    {
      "epoch": 0.94,
      "grad_norm": 8.716268539428711,
      "learning_rate": 1.8563488260661237e-05,
      "loss": 3.2879,
      "step": 2000
    },
    {
      "epoch": 1.0,
      "eval_bleu": 3.6755,
      "eval_gen_len": 9.6,
      "eval_loss": 3.0263478755950928,
      "eval_runtime": 55.0508,
      "eval_samples_per_second": 44.341,
      "eval_steps_per_second": 5.558,
      "step": 2137
    },
    {
      "epoch": 1.17,
      "grad_norm": 8.88276481628418,
      "learning_rate": 1.8085289889793963e-05,
      "loss": 3.0832,
      "step": 2500
    },
    {
      "epoch": 1.4,
      "grad_norm": 9.350152969360352,
      "learning_rate": 1.7606133205558218e-05,
      "loss": 2.9752,
      "step": 3000
    },
    {
      "epoch": 1.64,
      "grad_norm": 9.66445541381836,
      "learning_rate": 1.7127934834690944e-05,
      "loss": 2.919,
      "step": 3500
    },
    {
      "epoch": 1.87,
      "grad_norm": 9.777843475341797,
      "learning_rate": 1.6648778150455202e-05,
      "loss": 2.8624,
      "step": 4000
    },
    {
      "epoch": 2.0,
      "eval_bleu": 6.1855,
      "eval_gen_len": 9.0,
      "eval_loss": 2.704172372817993,
      "eval_runtime": 51.8946,
      "eval_samples_per_second": 47.038,
      "eval_steps_per_second": 5.897,
      "step": 4274
    },
    {
      "epoch": 2.11,
      "grad_norm": 8.302364349365234,
      "learning_rate": 1.6169621466219456e-05,
      "loss": 2.7279,
      "step": 4500
    },
    {
      "epoch": 2.34,
      "grad_norm": 9.186137199401855,
      "learning_rate": 1.569046478198371e-05,
      "loss": 2.628,
      "step": 5000
    },
    {
      "epoch": 2.57,
      "grad_norm": 9.202366828918457,
      "learning_rate": 1.5211308097747966e-05,
      "loss": 2.5855,
      "step": 5500
    },
    {
      "epoch": 2.81,
      "grad_norm": 7.704167366027832,
      "learning_rate": 1.4732151413512219e-05,
      "loss": 2.5952,
      "step": 6000
    },
    {
      "epoch": 3.0,
      "eval_bleu": 7.6863,
      "eval_gen_len": 8.7,
      "eval_loss": 2.5359957218170166,
      "eval_runtime": 50.2348,
      "eval_samples_per_second": 48.592,
      "eval_steps_per_second": 6.091,
      "step": 6411
    },
    {
      "epoch": 3.04,
      "grad_norm": 8.882967948913574,
      "learning_rate": 1.4252994729276475e-05,
      "loss": 2.5064,
      "step": 6500
    },
    {
      "epoch": 3.28,
      "grad_norm": 10.128954887390137,
      "learning_rate": 1.377383804504073e-05,
      "loss": 2.3854,
      "step": 7000
    },
    {
      "epoch": 3.51,
      "grad_norm": 11.200069427490234,
      "learning_rate": 1.3295639674173455e-05,
      "loss": 2.3721,
      "step": 7500
    },
    {
      "epoch": 3.74,
      "grad_norm": 10.064866065979004,
      "learning_rate": 1.2816482989937711e-05,
      "loss": 2.3861,
      "step": 8000
    },
    {
      "epoch": 3.98,
      "grad_norm": 9.399773597717285,
      "learning_rate": 1.2337326305701967e-05,
      "loss": 2.3368,
      "step": 8500
    },
    {
      "epoch": 4.0,
      "eval_bleu": 8.1272,
      "eval_gen_len": 8.9,
      "eval_loss": 2.440605640411377,
      "eval_runtime": 53.5721,
      "eval_samples_per_second": 45.565,
      "eval_steps_per_second": 5.712,
      "step": 8548
    },
    {
      "epoch": 4.21,
      "grad_norm": 9.387852668762207,
      "learning_rate": 1.185816962146622e-05,
      "loss": 2.2202,
      "step": 9000
    },
    {
      "epoch": 4.45,
      "grad_norm": 9.519303321838379,
      "learning_rate": 1.1379971250598946e-05,
      "loss": 2.2103,
      "step": 9500
    },
    {
      "epoch": 4.68,
      "grad_norm": 8.13349723815918,
      "learning_rate": 1.0900814566363202e-05,
      "loss": 2.1963,
      "step": 10000
    },
    {
      "epoch": 4.91,
      "grad_norm": 9.46871566772461,
      "learning_rate": 1.0421657882127456e-05,
      "loss": 2.2319,
      "step": 10500
    },
    {
      "epoch": 5.0,
      "eval_bleu": 8.9153,
      "eval_gen_len": 8.7,
      "eval_loss": 2.3764803409576416,
      "eval_runtime": 51.0539,
      "eval_samples_per_second": 47.812,
      "eval_steps_per_second": 5.994,
      "step": 10685
    },
    {
      "epoch": 5.15,
      "grad_norm": 8.655122756958008,
      "learning_rate": 9.942501197891712e-06,
      "loss": 2.1473,
      "step": 11000
    },
    {
      "epoch": 5.38,
      "grad_norm": 7.11079740524292,
      "learning_rate": 9.464302827024437e-06,
      "loss": 2.086,
      "step": 11500
    },
    {
      "epoch": 5.62,
      "grad_norm": 9.353837966918945,
      "learning_rate": 8.985146142788691e-06,
      "loss": 2.0976,
      "step": 12000
    },
    {
      "epoch": 5.85,
      "grad_norm": 6.686848163604736,
      "learning_rate": 8.505989458552947e-06,
      "loss": 2.1031,
      "step": 12500
    },
    {
      "epoch": 6.0,
      "eval_bleu": 9.8044,
      "eval_gen_len": 8.4,
      "eval_loss": 2.33703875541687,
      "eval_runtime": 49.9186,
      "eval_samples_per_second": 48.9,
      "eval_steps_per_second": 6.13,
      "step": 12822
    },
    {
      "epoch": 6.08,
      "grad_norm": 10.69469928741455,
      "learning_rate": 8.026832774317203e-06,
      "loss": 2.0385,
      "step": 13000
    },
    {
      "epoch": 6.32,
      "grad_norm": 10.524855613708496,
      "learning_rate": 7.548634403449929e-06,
      "loss": 2.0135,
      "step": 13500
    },
    {
      "epoch": 6.55,
      "grad_norm": 8.960298538208008,
      "learning_rate": 7.069477719214184e-06,
      "loss": 1.9854,
      "step": 14000
    },
    {
      "epoch": 6.79,
      "grad_norm": 8.376558303833008,
      "learning_rate": 6.590321034978438e-06,
      "loss": 1.9882,
      "step": 14500
    },
    {
      "epoch": 7.0,
      "eval_bleu": 10.9335,
      "eval_gen_len": 8.3,
      "eval_loss": 2.305778980255127,
      "eval_runtime": 46.9826,
      "eval_samples_per_second": 51.955,
      "eval_steps_per_second": 6.513,
      "step": 14959
    },
    {
      "epoch": 7.02,
      "grad_norm": 8.37325382232666,
      "learning_rate": 6.111164350742693e-06,
      "loss": 2.0022,
      "step": 15000
    },
    {
      "epoch": 7.25,
      "grad_norm": 10.654082298278809,
      "learning_rate": 5.63296597987542e-06,
      "loss": 1.9269,
      "step": 15500
    },
    {
      "epoch": 7.49,
      "grad_norm": 9.108884811401367,
      "learning_rate": 5.153809295639674e-06,
      "loss": 1.9231,
      "step": 16000
    },
    {
      "epoch": 7.72,
      "grad_norm": 11.080550193786621,
      "learning_rate": 4.674652611403929e-06,
      "loss": 1.9386,
      "step": 16500
    },
    {
      "epoch": 7.96,
      "grad_norm": 9.465530395507812,
      "learning_rate": 4.196454240536656e-06,
      "loss": 1.9382,
      "step": 17000
    },
    {
      "epoch": 8.0,
      "eval_bleu": 10.0827,
      "eval_gen_len": 8.7,
      "eval_loss": 2.2877209186553955,
      "eval_runtime": 51.6707,
      "eval_samples_per_second": 47.241,
      "eval_steps_per_second": 5.922,
      "step": 17096
    },
    {
      "epoch": 8.19,
      "grad_norm": 11.901007652282715,
      "learning_rate": 3.7172975563009106e-06,
      "loss": 1.8812,
      "step": 17500
    },
    {
      "epoch": 8.42,
      "grad_norm": 8.55168628692627,
      "learning_rate": 3.2381408720651656e-06,
      "loss": 1.8691,
      "step": 18000
    },
    {
      "epoch": 8.66,
      "grad_norm": 8.690796852111816,
      "learning_rate": 2.7589841878294203e-06,
      "loss": 1.8847,
      "step": 18500
    },
    {
      "epoch": 8.89,
      "grad_norm": 10.353960037231445,
      "learning_rate": 2.2798275035936753e-06,
      "loss": 1.8867,
      "step": 19000
    },
    {
      "epoch": 9.0,
      "eval_bleu": 10.561,
      "eval_gen_len": 8.5,
      "eval_loss": 2.2801945209503174,
      "eval_runtime": 50.0438,
      "eval_samples_per_second": 48.777,
      "eval_steps_per_second": 6.115,
      "step": 19233
    },
    {
      "epoch": 9.12,
      "grad_norm": 12.025863647460938,
      "learning_rate": 1.8006708193579304e-06,
      "loss": 1.8702,
      "step": 19500
    },
    {
      "epoch": 9.36,
      "grad_norm": 10.828529357910156,
      "learning_rate": 1.321514135122185e-06,
      "loss": 1.8405,
      "step": 20000
    },
    {
      "epoch": 9.59,
      "grad_norm": 8.913739204406738,
      "learning_rate": 8.423574508864399e-07,
      "loss": 1.8285,
      "step": 20500
    },
    {
      "epoch": 9.83,
      "grad_norm": 10.748685836791992,
      "learning_rate": 3.641590800191663e-07,
      "loss": 1.8456,
      "step": 21000
    },
    {
      "epoch": 10.0,
      "eval_bleu": 10.56,
      "eval_gen_len": 8.6,
      "eval_loss": 2.2771260738372803,
      "eval_runtime": 50.5954,
      "eval_samples_per_second": 48.245,
      "eval_steps_per_second": 6.048,
      "step": 21370
    },
    {
      "epoch": 10.0,
      "step": 21370,
      "total_flos": 1319076481204224.0,
      "train_loss": 2.351140513774888,
      "train_runtime": 1146.4747,
      "train_samples_per_second": 149.109,
      "train_steps_per_second": 18.64
    }
  ],
  "logging_steps": 500,
  "max_steps": 21370,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1.0,
  "total_flos": 1319076481204224.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
